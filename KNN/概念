麦子学院视频+西瓜书推导+b站视频资源

knn算法，可称为：最近邻规则分类。
  1. 综述
     1.1 Cover和Hart在1968年提出了最初的邻近算法
     1.2 分类(classification)算法
     1.3 输入基于实例的学习(instance-based learning), 懒惰学习(lazy learning)
     
    懒惰学习：是指在训练阶段，仅仅把样本保存起来，（不进行训练），训练时间开销为零。待收到测试样本后，在进行处理。
             而那些在训练阶段就对样本进行进行学习处理的方法称为急切学习。（西瓜书P225）
             
  2.工作机制：
        对给定的测试样本，基于某种距离度量，找出训练集中与其最靠近的k个训练样本，然后基于这k个邻居的信息来进行预测。
     2.1分类任务
        投票法：即选择k个样本中出现最多的类别标记作为预测结果
     2.2回归任务
        平均法：将这k个样本的实值输出标记的平均值作为预测结果
     此外，还有基于距离远近进行加权平均或加权投票，距离越近的样本权重越大。（西瓜书P225）
     注：当样本分布不均衡时可考虑。
     
  3.算法详述
    3.1 步骤：
     为了判断未知实例的类别，以所有已知类别的实例作为参照      （对所有实例，都要计算）
     选择参数K  （一般为奇数：1，3,5,7...）
     计算未知实例与所有已知实例的距离 
     选择最近K个已知实例 （对距离进行排序，取前k个）
     根据少数服从多数的投票法则(majority-voting)，让未知实例归类为K个最邻近样本中最多数的类别
     
    3.2 细节:
        关于K
        关于距离的衡量方法:
        Euclidean Distance  (平面上两点间距离)
        余弦值 （cos）
        相关度 （correlation）
        曼哈顿距离 （Manhattan distance）
        
    4.算法优缺点：
        4.1 算法优点
            简单
            易于理解
            容易实现
            通过对K的选择可具备丢噪音数据的健壮性
        4.2 算法缺点
            需要大量空间储存所有已知实例 （有测试样例才进行计算）
            算法复杂度高（需要比较所有已知实例与要分类的实例）
            当其样本分布不平衡时，比如其中一类样本过大（实例数量过多）占主导的时候，
              新的未知实例容易被归类为这个主导样本，因为这类样本实例的数量过大，
              但这个新的未知实例实际并木接近目标样本。
    

    5. 改进版本
           考虑距离，根据距离加上权重
           比如: 1/d (d: 距离 
         
            
